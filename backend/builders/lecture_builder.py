#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–ü–æ—Å—Ç—Ä–æ–∏—Ç–µ–ª—å –ª–µ–∫—Ü–∏–∏ –∏–∑ –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤ PDF.

–ì—Ä—É–ø–ø–∏—Ä—É–µ—Ç —ç–ª–µ–º–µ–Ω—Ç—ã –≤ –∞–±–∑–∞—Ü—ã, –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∑–∞–≥–æ–ª–æ–≤–∫–∏ –∏ —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ª–µ–∫—Ü–∏–∏.
"""

import sys
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple
import uuid
import statistics
import logging
import shutil
import base64
import re

# –î–æ–±–∞–≤–ª—è–µ–º —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ –ø—É—Ç—å –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞
parent_dir = Path(__file__).parent.parent.parent
sys.path.insert(0, str(parent_dir))

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –º–æ–¥–µ–ª–∏
sys.path.insert(0, str(Path(__file__).parent.parent))
from models.lecture_model import (
    Lecture, LectureSection, LecturePage,
    TextBlock, ImageBlock, ListBlock, TableBlock,
    ParsedElement
)


def build_lecture(elements: List[ParsedElement], output_images_dir: Optional[Path] = None) -> Lecture:
    """
    –°—Ç—Ä–æ–∏—Ç –º–æ–¥–µ–ª—å –ª–µ–∫—Ü–∏–∏ –∏–∑ –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤ PDF.
    
    Args:
        elements: –°–ø–∏—Å–æ–∫ ParsedElement (–∞—Ç–æ–º–∞—Ä–Ω—ã–µ spans) –≤ –ø–æ—Ä—è–¥–∫–µ –∏—Ö –ø–æ—è–≤–ª–µ–Ω–∏—è –≤ PDF
        output_images_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (–µ—Å–ª–∏ None, —Å–æ–∑–¥–∞–µ—Ç—Å—è images/ –≤ –∫–æ—Ä–Ω–µ –ø—Ä–æ–µ–∫—Ç–∞)
    
    Returns:
        Lecture - —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –ª–µ–∫—Ü–∏–∏
    """
    if not elements:
        raise ValueError("–°–ø–∏—Å–æ–∫ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –ø—É—Å—Ç")
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: –µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω–∞, —Å–æ–∑–¥–∞–µ–º images/ –≤ –∫–æ—Ä–Ω–µ –ø—Ä–æ–µ–∫—Ç–∞
    if output_images_dir is None:
        # –ö–æ—Ä–µ–Ω—å –ø—Ä–æ–µ–∫—Ç–∞ - –Ω–∞ 3 —É—Ä–æ–≤–Ω—è –≤—ã—à–µ –æ—Ç —ç—Ç–æ–≥–æ —Ñ–∞–π–ª–∞ (backend/builders/lecture_builder.py)
        project_root = Path(__file__).parent.parent.parent
        output_images_dir = project_root / "images"
    # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É images/ –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
    output_images_dir.mkdir(parents=True, exist_ok=True)
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: —Å–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–∞ –¥–∏—Å–∫ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—É—Ç–∏
    _normalize_image_paths(elements, output_images_dir)
    
    # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ spans –≤ —Å—Ç—Ä–æ–∫–∏ –∏ –∞–±–∑–∞—Ü—ã
    paragraphs, images = _normalize_elements_to_paragraphs(elements)
    
    # –°—á–∏—Ç–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —à—Ä–∏—Ñ—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–±–∑–∞—Ü–µ–≤
    text_paragraphs = [p for p in paragraphs if p['type'] == 'text']
    if not text_paragraphs:
        return _build_lecture_from_images_only(elements)
    
    # –í—ã—á–∏—Å–ª—è–µ–º –º–µ–¥–∏–∞–Ω–Ω—ã–π —Ä–∞–∑–º–µ—Ä —à—Ä–∏—Ñ—Ç–∞ –∏–∑ –∞–±–∑–∞—Ü–µ–≤
    paragraph_font_sizes = [p['avg_font_size'] for p in text_paragraphs]
    median_font_size = statistics.median(paragraph_font_sizes) if paragraph_font_sizes else 12.0
    avg_font_size = statistics.mean(paragraph_font_sizes) if paragraph_font_sizes else 12.0
    
    # –ü–æ—Ä–æ–≥ –¥–ª—è –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
    std_font_size = statistics.stdev(paragraph_font_sizes) if len(paragraph_font_sizes) > 1 else 0
    header_threshold = max(median_font_size * 1.3, avg_font_size + 1.5 * std_font_size)
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ –Ω–∞ —É—Ä–æ–≤–Ω–µ –∞–±–∑–∞—Ü–µ–≤
    headers = _identify_headers_from_paragraphs(paragraphs, header_threshold, median_font_size)
    
    # –ü–µ—Ä–≤—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ ‚Üí Lecture.title
    lecture_title = _extract_lecture_title_from_paragraphs(paragraphs, headers)
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
    description = _generate_description_from_paragraphs(paragraphs, headers)
    language = _detect_language_from_paragraphs(paragraphs)
    keywords = _extract_keywords_from_paragraphs(paragraphs, headers)
    
    # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ª–µ–∫—Ü–∏–∏
    lecture = Lecture(
        title=lecture_title,
        description=description,
        language=language
    )
    lecture.metadata["keywords"] = keywords
    
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –∞–±–∑–∞—Ü—ã –ø–æ —Ä–∞–∑–¥–µ–ª–∞–º –∏ —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º
    sections = _build_sections_from_paragraphs(paragraphs, headers, header_threshold, images)
    
    for section in sections:
        lecture.add_section(section)
    
    return lecture


def _normalize_image_paths(elements: List[ParsedElement], output_images_dir: Path) -> None:
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: –∫–æ–ø–∏—Ä—É–µ—Ç —Ñ–∞–π–ª—ã, –¥–µ–∫–æ–¥–∏—Ä—É–µ—Ç base64/blob –∏ –æ–±–Ω–æ–≤–ª—è–µ—Ç –ø—É—Ç–∏.
    
    –í—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –≤ output_images_dir —Å —É–Ω–∏–∫–∞–ª—å–Ω—ã–º–∏ –∏–º–µ–Ω–∞–º–∏ (img_{uuid4()}.ext).
    –ü–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤—Å–µ ParsedElement.image_path –Ω–∞—á–∏–Ω–∞—é—Ç—Å—è —Å "images/" (–æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ –ø—É—Ç–∏).
    
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç:
    - Base64 –¥–∞–Ω–Ω—ã–µ (data:image/...;base64,...) ‚Üí –¥–µ–∫–æ–¥–∏—Ä—É–µ—Ç –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –∫–∞–∫ —Ñ–∞–π–ª
    - –õ–æ–∫–∞–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã (–∞–±—Å–æ–ª—é—Ç–Ω—ã–µ –ø—É—Ç–∏) ‚Üí –∫–æ–ø–∏—Ä—É–µ—Ç –≤ images/ —Å –Ω–æ–≤—ã–º –∏–º–µ–Ω–µ–º
    - –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ –ø—É—Ç–∏ ‚Üí –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç —Å –ø—Ä–µ—Ñ–∏–∫—Å–æ–º images/
    - Blob URL ‚Üí –ª–æ–≥–∏—Ä—É–µ—Ç –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ (–Ω–µ –º–æ–≥—É—Ç –±—ã—Ç—å –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã –≤ Python)
    
    Args:
        elements: –°–ø–∏—Å–æ–∫ ParsedElement —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏
        output_images_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (images/ –≤ –∫–æ—Ä–Ω–µ –ø—Ä–æ–µ–∫—Ç–∞)
    """
    processed_count = 0
    skipped_count = 0
    error_count = 0
    
    for elem in elements:
        if elem.type != "image" or not elem.image_path:
            continue
        
        original_path = elem.image_path
        
        try:
            # –°–ª—É—á–∞–π 1: –ü—É—Ç—å —É–∂–µ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –∏ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å images/ - –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å
            if not Path(elem.image_path).is_absolute() and elem.image_path.startswith("images/"):
                processed_count += 1
                continue
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —É–Ω–∏–∫–∞–ª—å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞ —Å uuid4()
            unique_id = str(uuid.uuid4())
            
            # –°–ª—É—á–∞–π 2: Blob URL - –Ω–µ –º–æ–∂–µ–º –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –≤ Python (—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã –¥–ª—è –±—Ä–∞—É–∑–µ—Ä–∞)
            if elem.image_path.startswith("blob:"):
                logging.warning(f"‚ö†Ô∏è Blob URL –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –æ–±—Ä–∞–±–æ—Ç–∞–Ω –≤ Python (—Ç—Ä–µ–±—É–µ—Ç—Å—è –±—Ä–∞—É–∑–µ—Ä): {elem.image_path}")
                # –ü—Ä–æ–±—É–µ–º —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∫–∞–∫ placeholder –∏–ª–∏ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                # –í —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ blob URL –¥–æ–ª–∂–Ω—ã –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å—Å—è –Ω–∞ —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥–µ –ø–µ—Ä–µ–¥ –æ—Ç–ø—Ä–∞–≤–∫–æ–π
                skipped_count += 1
                continue
            
            # –°–ª—É—á–∞–π 3: Base64 –¥–∞–Ω–Ω—ã–µ (data:image/...;base64,...)
            if elem.image_path.startswith("data:image/"):
                try:
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º base64 –¥–∞–Ω–Ω—ã–µ
                    # –§–æ—Ä–º–∞—Ç: data:image/png;base64,iVBORw0KGgo...
                    match = re.match(r'data:image/(\w+);base64,(.+)', elem.image_path)
                    if match:
                        image_format = match.group(1).lower()
                        base64_data = match.group(2)
                        
                        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ–∞–π–ª–∞
                        ext_map = {'png': '.png', 'jpeg': '.jpg', 'jpg': '.jpg', 'gif': '.gif', 'webp': '.webp'}
                        ext = ext_map.get(image_format, '.png')
                        
                        # –î–µ–∫–æ–¥–∏—Ä—É–µ–º base64
                        image_bytes = base64.b64decode(base64_data)
                        
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª
                        image_filename = f"img_{unique_id}{ext}"
                        dest_path = output_images_dir / image_filename
                        
                        with open(dest_path, 'wb') as f:
                            f.write(image_bytes)
                        
                        # –û–±–Ω–æ–≤–ª—è–µ–º –ø—É—Ç—å –Ω–∞ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π
                        elem.image_path = f"images/{image_filename}"
                        processed_count += 1
                        continue
                    else:
                        logging.warning(f"‚ö†Ô∏è –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç base64 –¥–∞–Ω–Ω—ã—Ö: {elem.image_path[:50]}...")
                        skipped_count += 1
                        continue
                except Exception as e:
                    logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–∏ base64: {e}")
                    error_count += 1
                    continue
            
            # –°–ª—É—á–∞–π 4: –ê–±—Å–æ–ª—é—Ç–Ω—ã–π –ø—É—Ç—å - –∫–æ–ø–∏—Ä—É–µ–º —Ñ–∞–π–ª
            if Path(elem.image_path).is_absolute():
                source_path = Path(elem.image_path)
                if source_path.exists():
                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ–∞–π–ª–∞
                    ext = source_path.suffix or ".png"
                    image_filename = f"img_{unique_id}{ext}"
                    dest_path = output_images_dir / image_filename
                    
                    try:
                        shutil.copy2(source_path, dest_path)
                        # –û–±–Ω–æ–≤–ª—è–µ–º –ø—É—Ç—å –Ω–∞ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π
                        elem.image_path = f"images/{image_filename}"
                        processed_count += 1
                    except Exception as e:
                        logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è {source_path}: {e}")
                        error_count += 1
                else:
                    logging.warning(f"‚ö†Ô∏è –§–∞–π–ª –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω: {source_path}")
                    skipped_count += 1
                continue
            
            # –°–ª—É—á–∞–π 5: –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –ø—É—Ç—å (–Ω–µ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å images/)
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –µ–≥–æ, –¥–æ–±–∞–≤–ª—è—è –ø—Ä–µ—Ñ–∏–∫—Å images/
            image_filename = Path(elem.image_path).name
            elem.image_path = f"images/{image_filename}"
            processed_count += 1
            
        except Exception as e:
            logging.error(f"‚ùå –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è {original_path}: {e}")
            error_count += 1
            continue
    


def _normalize_elements_to_paragraphs(elements: List[ParsedElement]) -> List[Dict[str, Any]]:
    """
    –ü—Ä–µ–¥–Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —ç–ª–µ–º–µ–Ω—Ç–æ–≤.
    
    1. –°–æ—Ä—Ç–∏—Ä—É–µ—Ç spans –ø–æ (page_number, normalized_y, x0)
    2. –ì—Ä—É–ø–ø–∏—Ä—É–µ—Ç spans –≤ —Å—Ç—Ä–æ–∫–∏ –ø–æ line_id
    3. –ì—Ä—É–ø–ø–∏—Ä—É–µ—Ç —Å—Ç—Ä–æ–∫–∏ –≤ –∞–±–∑–∞—Ü—ã –ø–æ –±–ª–∏–∑–æ—Å—Ç–∏ Y, font_size, is_bold
    
    Returns:
        –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π-–∞–±–∑–∞—Ü–µ–≤: {
            'type': 'text' | 'image',
            'spans': List[ParsedElement],
            'text': str,
            'avg_font_size': float,
            'is_bold': bool,
            'bbox': Tuple,
            'page_number': int,
            'is_header': bool,
            'header_level': int
        }
    """
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º spans –ø–æ (page_number, normalized_y, x0)
    def normalize_y(bbox: Tuple[float, float, float, float]) -> float:
        """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç Y –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—É –¥–ª—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ –≤ —Å—Ç—Ä–æ–∫–∏"""
        if not bbox or len(bbox) < 4:
            return 0.0
        # –û–∫—Ä—É–≥–ª—è–µ–º Y –¥–æ –±–ª–∏–∂–∞–π—à–∏—Ö 5 –ø–∏–∫—Å–µ–ª–µ–π –¥–ª—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ –≤ —Å—Ç—Ä–æ–∫–∏
        return round(bbox[1] / 5.0) * 5.0
    
    sorted_elements = sorted(
        elements,
        key=lambda e: (
            e.page_number,
            normalize_y(e.bbox) if e.bbox and len(e.bbox) >= 4 else 0,
            e.bbox[0] if e.bbox and len(e.bbox) >= 4 else 0
        )
    )
    
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º spans –≤ —Å—Ç—Ä–æ–∫–∏ –ø–æ line_id (page_number + normalized_y)
    lines = []
    current_line = []
    current_line_id = None
    
    for elem in sorted_elements:
        if elem.type != "text" or not elem.text:
            # –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ—Ç–¥–µ–ª—å–Ω–æ
            continue
        
        line_id = (elem.page_number, normalize_y(elem.bbox) if elem.bbox and len(elem.bbox) >= 4 else 0)
        
        if current_line_id is None or line_id != current_line_id:
            # –ù–æ–≤–∞—è —Å—Ç—Ä–æ–∫–∞
            if current_line:
                lines.append(current_line)
            current_line = [elem]
            current_line_id = line_id
        else:
            # –ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Å—Ç—Ä–æ–∫–∏
            current_line.append(elem)
    
    if current_line:
        lines.append(current_line)
    
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º —Å—Ç—Ä–æ–∫–∏ –≤ –∞–±–∑–∞—Ü—ã
    # –°–Ω–∞—á–∞–ª–∞ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ vertical_gap –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –º–µ–¥–∏–∞–Ω–Ω–æ–≥–æ gap
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –†–ï–ê–õ–¨–ù–´–ï –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã bbox, –∞ –Ω–µ normalized_y
    vertical_gaps = []
    for i in range(1, len(lines)):
        if not lines[i] or not lines[i-1]:
            continue
        curr_line_spans = lines[i]
        prev_line_spans = lines[i-1]
        if (curr_line_spans and prev_line_spans and
            curr_line_spans[0].page_number == prev_line_spans[0].page_number):
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã bbox –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è gap
            curr_bbox = curr_line_spans[0].bbox
            prev_bbox = prev_line_spans[0].bbox
            if (curr_bbox and len(curr_bbox) >= 4 and 
                prev_bbox and len(prev_bbox) >= 4):
                # Gap = —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –æ—Ç –Ω–∏–∂–Ω–µ–π –≥—Ä–∞–Ω–∏—Ü—ã –ø—Ä–µ–¥—ã–¥—É—â–µ–π —Å—Ç—Ä–æ–∫–∏ –¥–æ –≤–µ—Ä—Ö–Ω–µ–π –≥—Ä–∞–Ω–∏—Ü—ã —Ç–µ–∫—É—â–µ–π
                gap = curr_bbox[1] - prev_bbox[3]  # y0_current - y1_prev
                if gap > 0 and gap < 100:  # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ –∏ –æ—á–µ–Ω—å –±–æ–ª—å—à–∏–µ gaps
                    vertical_gaps.append(gap)
    
    # –í—ã—á–∏—Å–ª—è–µ–º –º–µ–¥–∏–∞–Ω–Ω—ã–π gap
    median_gap = statistics.median(vertical_gaps) if vertical_gaps else 15.0
    # –¢–∞–∫–∂–µ –≤—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω–∏–π gap –¥–ª—è –±–æ–ª–µ–µ —Ç–æ—á–Ω–æ–π –æ—Ü–µ–Ω–∫–∏
    avg_gap = statistics.mean(vertical_gaps) if vertical_gaps else 15.0
    
    paragraphs = []
    current_paragraph = []
    
    for line_idx, line in enumerate(lines):
        if not line:
            continue
        
        # –°–≤–æ–π—Å—Ç–≤–∞ —Å—Ç—Ä–æ–∫–∏
        line_spans = line
        line_font_sizes = [s.font_size for s in line_spans]
        line_avg_font_size = statistics.mean(line_font_sizes) if line_font_sizes else 12.0
        line_is_bold = all(s.is_bold for s in line_spans if s.type == "text")
        line_bbox = line_spans[0].bbox if line_spans[0].bbox and len(line_spans[0].bbox) >= 4 else None
        line_page = line_spans[0].page_number
        
        # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç —Å—Ç—Ä–æ–∫–∏ –¥–ª—è —ç–≤—Ä–∏—Å—Ç–∏–∫
        line_text = " ".join([s.text for s in line_spans if s.text]).strip()
        line_starts_with_capital = line_text and line_text[0].isupper() if line_text else False
        
        if not current_paragraph:
            # –ü–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ - –Ω–∞—á–∏–Ω–∞–µ–º –Ω–æ–≤—ã–π –∞–±–∑–∞—Ü
            current_paragraph = [line]
        else:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –º–æ–∂–Ω–æ –ª–∏ –¥–æ–±–∞–≤–∏—Ç—å —Å—Ç—Ä–æ–∫—É –≤ —Ç–µ–∫—É—â–∏–π –∞–±–∑–∞—Ü
            prev_line = current_paragraph[-1]
            prev_line_spans = prev_line
            prev_line_bbox = prev_line_spans[0].bbox if prev_line_spans[0].bbox and len(prev_line_spans[0].bbox) >= 4 else None
            prev_line_page = prev_line_spans[0].page_number
            prev_line_font_sizes = [s.font_size for s in prev_line_spans]
            prev_line_avg_font_size = statistics.mean(prev_line_font_sizes) if prev_line_font_sizes else 12.0
            prev_line_is_bold = all(s.is_bold for s in prev_line_spans if s.type == "text")
            
            # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç –ø—Ä–µ–¥—ã–¥—É—â–µ–π —Å—Ç—Ä–æ–∫–∏ –¥–ª—è —ç–≤—Ä–∏—Å—Ç–∏–∫
            prev_line_text = " ".join([s.text for s in prev_line_spans if s.text]).strip()
            prev_line_ends_with_period = prev_line_text and (prev_line_text.endswith('.') or prev_line_text.endswith('!') or prev_line_text.endswith('?')) if prev_line_text else False
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É—Å–ª–æ–≤–∏—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ –≤ –∞–±–∑–∞—Ü:
            same_page = line_page == prev_line_page
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –†–ï–ê–õ–¨–ù–´–ï –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã bbox –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è vertical_gap
            if line_bbox and prev_line_bbox:
                # Gap = —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –æ—Ç –Ω–∏–∂–Ω–µ–π –≥—Ä–∞–Ω–∏—Ü—ã –ø—Ä–µ–¥—ã–¥—É—â–µ–π —Å—Ç—Ä–æ–∫–∏ –¥–æ –≤–µ—Ä—Ö–Ω–µ–π –≥—Ä–∞–Ω–∏—Ü—ã —Ç–µ–∫—É—â–µ–π
                vertical_gap = line_bbox[1] - prev_line_bbox[3]  # y0_current - y1_prev
            else:
                vertical_gap = 0
            
            font_size_diff = abs(line_avg_font_size - prev_line_avg_font_size)
            same_bold = line_is_bold == prev_line_is_bold
            
            # –ö—Ä–∏—Ç–µ—Ä–∏–π 1: –ë–∞–∑–æ–≤—ã–µ —É—Å–ª–æ–≤–∏—è (—Ç–∞ –∂–µ —Å—Ç—Ä–∞–Ω–∏—Ü–∞, –±–ª–∏–∑–æ—Å—Ç—å, –æ–¥–∏–Ω–∞–∫–æ–≤—ã–π —Å—Ç–∏–ª—å)
            # –£–º–µ–Ω—å—à–∞–µ–º –ø–æ—Ä–æ–≥ vertical_gap –¥–ª—è –±–æ–ª–µ–µ —Å—Ç—Ä–æ–≥–æ–π –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏
            basic_conditions_met = (
                same_page and 
                vertical_gap < 15 and  # –£–º–µ–Ω—å—à–µ–Ω–æ —Å 20 –¥–æ 15 –¥–ª—è –±–æ–ª–µ–µ —Å—Ç—Ä–æ–≥–æ–π –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏
                font_size_diff < 2.0 and 
                same_bold
            )
            
            # –ö—Ä–∏—Ç–µ—Ä–∏–π 2: –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω—ã–π —Ä–∞–∑—Ä—ã–≤
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª–µ–µ —Å—Ç—Ä–æ–≥–∏–π –ø–æ—Ä–æ–≥: median_gap * 1.3 –≤–º–µ—Å—Ç–æ 1.5
            significant_gap = vertical_gap > max(median_gap * 1.3, avg_gap * 1.2) if vertical_gap > 0 else False
            
            # –ö—Ä–∏—Ç–µ—Ä–∏–π 3: –≠–≤—Ä–∏—Å—Ç–∏–∫–∞ –¥–ª—è –Ω–∞—á–∞–ª–∞ –Ω–æ–≤–æ–≥–æ –∞–±–∑–∞—Ü–∞
            # –°—Ç—Ä–æ–∫–∞ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å –∑–∞–≥–ª–∞–≤–Ω–æ–π + –ø—Ä–µ–¥—ã–¥—É—â–∞—è –∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è —Ç–æ—á–∫–æ–π + –µ—Å—Ç—å –æ—Ç—Å—Ç—É–ø
            heuristic_new_paragraph = (
                line_starts_with_capital and
                prev_line_ends_with_period and
                vertical_gap > 8  # –£–º–µ–Ω—å—à–µ–Ω–æ —Å 10 –¥–æ 8 –¥–ª—è –±–æ–ª–µ–µ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ–π —ç–≤—Ä–∏—Å—Ç–∏–∫–∏
            )
            
            # –ö—Ä–∏—Ç–µ—Ä–∏–π 4: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ - –æ—á–µ–Ω—å –±–æ–ª—å—à–æ–π –æ—Ç—Å—Ç—É–ø –≤—Å–µ–≥–¥–∞ —Ä–∞–∑—Ä—ã–≤–∞–µ—Ç –∞–±–∑–∞—Ü
            very_large_gap = vertical_gap > 25  # –û—á–µ–Ω—å –±–æ–ª—å—à–æ–π –æ—Ç—Å—Ç—É–ø (> 25px) –≤—Å–µ–≥–¥–∞ –Ω–æ–≤—ã–π –∞–±–∑–∞—Ü
            
            # –†–µ—à–µ–Ω–∏–µ: –ø—Ä–æ–¥–æ–ª–∂–∞—Ç—å –∞–±–∑–∞—Ü —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏:
            # - –±–∞–∑–æ–≤—ã–µ —É—Å–ª–æ–≤–∏—è –≤—ã–ø–æ–ª–Ω–µ–Ω—ã
            # - –ò –Ω–µ—Ç —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —Ä–∞–∑—Ä—ã–≤–∞
            # - –ò –Ω–µ—Ç —ç–≤—Ä–∏—Å—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞ –Ω–æ–≤–æ–≥–æ –∞–±–∑–∞—Ü–∞
            # - –ò –Ω–µ—Ç –æ—á–µ–Ω—å –±–æ–ª—å—à–æ–≥–æ –æ—Ç—Å—Ç—É–ø–∞
            if (basic_conditions_met and 
                not significant_gap and 
                not heuristic_new_paragraph and
                not very_large_gap):
                # –ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –∞–±–∑–∞—Ü–∞
                current_paragraph.append(line)
            else:
                # –ù–æ–≤—ã–π –∞–±–∑–∞—Ü
                paragraphs.append(_create_paragraph_dict(current_paragraph, len(current_paragraph)))
                current_paragraph = [line]
    
    if current_paragraph:
        paragraphs.append(_create_paragraph_dict(current_paragraph, len(current_paragraph)))
    
    # –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Ö—Ä–∞–Ω–∏–º –æ—Ç–¥–µ–ª—å–Ω–æ, –Ω–µ –¥–æ–±–∞–≤–ª—è–µ–º –≤ paragraphs
    images = [e for e in sorted_elements if e.type == "image"]
    
    # –î–æ–±–∞–≤–ª—è–µ–º global_index –∫–∞–∂–¥–æ–º—É –∞–±–∑–∞—Ü—É
    for idx, para in enumerate(paragraphs):
        para['global_index'] = idx
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –∞–±–∑–∞—Ü—ã –ø–æ –ø–æ–∑–∏—Ü–∏–∏
    paragraphs.sort(key=lambda p: (p['page_number'], p['bbox'][1] if p['bbox'] and len(p['bbox']) >= 4 else 0))
    
    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∞–±–∑–∞—Ü—ã –∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –æ—Ç–¥–µ–ª—å–Ω–æ
    return paragraphs, images


def _create_paragraph_dict(lines: List[List[ParsedElement]], num_lines: int) -> Dict[str, Any]:
    """
    –°–æ–∑–¥–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å-–∞–±–∑–∞—Ü –∏–∑ —Å–ø–∏—Å–∫–∞ —Å—Ç—Ä–æ–∫.
    
    Args:
        lines: –°–ø–∏—Å–æ–∫ —Å—Ç—Ä–æ–∫ (–∫–∞–∂–¥–∞—è —Å—Ç—Ä–æ–∫–∞ - —Å–ø–∏—Å–æ–∫ spans)
        num_lines: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ –≤ –∞–±–∑–∞—Ü–µ (–Ω–∞ –æ—Å–Ω–æ–≤–µ line_id, –Ω–µ len(spans))
    """
    all_spans = []
    for line in lines:
        all_spans.extend(line)
    
    if not all_spans:
        return {
            'type': 'text',
            'spans': [],
            'text': '',
            'avg_font_size': 12.0,
            'is_bold': False,
            'bbox': (0, 0, 0, 0),
            'page_number': 0,
            'is_header': False,
            'header_level': 0,
            'num_lines': 0,  # –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ –Ω–∞ –æ—Å–Ω–æ–≤–µ line_id
            'global_index': -1  # –±—É–¥–µ—Ç —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ–∑–∂–µ
        }
    
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ç–µ–∫—Å—Ç
    paragraph_text = " ".join([s.text for s in all_spans if s.text])
    
    # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä —à—Ä–∏—Ñ—Ç–∞
    font_sizes = [s.font_size for s in all_spans if s.type == "text"]
    avg_font_size = statistics.mean(font_sizes) if font_sizes else 12.0
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –≤—Å–µ –ª–∏ spans –∂–∏—Ä–Ω—ã–µ
    is_bold = all(s.is_bold for s in all_spans if s.type == "text")
    
    # –í—ã—á–∏—Å–ª—è–µ–º –æ–±—â–∏–π bbox
    bboxes = [s.bbox for s in all_spans if s.bbox and len(s.bbox) >= 4]
    if bboxes:
        x0 = min(b[0] for b in bboxes)
        y0 = min(b[1] for b in bboxes)
        x1 = max(b[2] for b in bboxes)
        y1 = max(b[3] for b in bboxes)
        bbox = (x0, y0, x1, y1)
    else:
        bbox = (0, 0, 0, 0)
    
    page_number = all_spans[0].page_number
    
    return {
        'type': 'text',
        'spans': all_spans,
        'text': paragraph_text,
        'avg_font_size': avg_font_size,
        'is_bold': is_bold,
        'bbox': bbox,
        'page_number': page_number,
        'is_header': False,  # –ë—É–¥–µ—Ç –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ –ø–æ–∑–∂–µ
        'header_level': 0,
        'num_lines': num_lines,  # –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ –Ω–∞ –æ—Å–Ω–æ–≤–µ line_id
        'global_index': -1  # –±—É–¥–µ—Ç —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ–∑–∂–µ
    }


def _identify_headers_from_paragraphs(
    paragraphs: List[Dict[str, Any]],
    header_threshold: float,
    median_font_size: float
) -> List[Dict[str, Any]]:
    """
    –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∑–∞–≥–æ–ª–æ–≤–∫–∏ –Ω–∞ —É—Ä–æ–≤–Ω–µ –∞–±–∑–∞—Ü–µ–≤.
    
    –ó–∞–≥–æ–ª–æ–≤–æ–∫ = –∞–±–∑–∞—Ü, –≥–¥–µ:
    - —Å—Ä–µ–¥–Ω–∏–π font_size > –º–µ–¥–∏–∞–Ω–Ω–æ–≥–æ (–∏–ª–∏ >= header_threshold)
    - –∏–ª–∏ –≤—Å–µ spans –∂–∏—Ä–Ω—ã–µ
    - –∞–±–∑–∞—Ü –∫–æ—Ä–æ—Ç–∫–∏–π (1-2 —Å—Ç—Ä–æ–∫–∏)
    
    Returns:
        –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π: {'index': int, 'level': int, 'text': str, 'paragraph': dict}
    """
    headers = []
    
    for idx, para in enumerate(paragraphs):
        if para['type'] != 'text' or not para['text']:
            continue
        
        text = para['text'].strip()
        if not text:
            continue
        
        is_header = False
        level = 0
        
        # –ö—Ä–∏—Ç–µ—Ä–∏–π 1: –°—Ä–µ–¥–Ω–∏–π font_size >= header_threshold
        if para['avg_font_size'] >= header_threshold:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º num_lines –Ω–∞ –æ—Å–Ω–æ–≤–µ line_id, –∞ –Ω–µ len(spans)
            num_lines = para.get('num_lines', 0)
            if num_lines <= 2 and len(text) <= 150:  # –ö–æ—Ä–æ—Ç–∫–∏–π –∞–±–∑–∞—Ü (1-2 —Å—Ç—Ä–æ–∫–∏)
                is_header = True
                if para['avg_font_size'] >= header_threshold * 1.5:
                    level = 1
                else:
                    level = 2
        
        # –ö—Ä–∏—Ç–µ—Ä–∏–π 2: –í—Å–µ spans –∂–∏—Ä–Ω—ã–µ + –∫–æ—Ä–æ—Ç–∫–∏–π –∞–±–∑–∞—Ü
        if not is_header and para['is_bold']:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º num_lines –Ω–∞ –æ—Å–Ω–æ–≤–µ line_id
            num_lines = para.get('num_lines', 0)
            if num_lines <= 2 and len(text) <= 150:
                is_header = True
                level = 1
        
        # –ö—Ä–∏—Ç–µ—Ä–∏–π 3: –ö–æ—Ä–æ—Ç–∫–∏–π –∞–±–∑–∞—Ü + –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å –∑–∞–≥–ª–∞–≤–Ω–æ–π + –±–µ–∑ —Ç–æ—á–∫–∏ –≤ –∫–æ–Ω—Ü–µ
        if not is_header:
            if (len(text) <= 100 and 
                len(text) > 3 and
                text[0].isupper() and
                not text.endswith('.') and
                not text.endswith(',') and
                para['avg_font_size'] >= median_font_size * 0.9):
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã–π –æ—Ç—Å—Ç—É–ø –æ—Ç –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –∞–±–∑–∞—Ü–∞
                if idx > 0:
                    prev_para = paragraphs[idx - 1]
                    if prev_para['type'] == 'text' and prev_para['bbox'] and para['bbox']:
                        if len(prev_para['bbox']) >= 4 and len(para['bbox']) >= 4:
                            vertical_gap = para['bbox'][1] - prev_para['bbox'][3]
                            if vertical_gap > 20:
                                is_header = True
                                level = 1
        
        if is_header:
            # –û–±—Ä–µ–∑–∞–µ–º —Ç–µ–∫—Å—Ç –∑–∞–≥–æ–ª–æ–≤–∫–∞
            header_text = text
            if '\n' in header_text:
                header_text = header_text.split('\n')[0].strip()
            elif len(header_text) > 100:
                header_text = header_text[:100].rsplit(' ', 1)[0].strip()
            
            # –ü–æ–º–µ—á–∞–µ–º –∞–±–∑–∞—Ü –∫–∞–∫ –∑–∞–≥–æ–ª–æ–≤–æ–∫
            para['is_header'] = True
            para['header_level'] = level
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º global_index, –∞ –Ω–µ –ª–æ–∫–∞–ª—å–Ω—ã–π –∏–Ω–¥–µ–∫—Å —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            headers.append({
                'index': para.get('global_index', idx),  # –ò—Å–ø–æ–ª—å–∑—É–µ–º global_index
                'level': level,
                'text': header_text,
                'paragraph': para
            })
    
    return headers


def _extract_lecture_title_from_paragraphs(
    paragraphs: List[Dict[str, Any]],
    headers: List[Dict[str, Any]]
) -> str:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∑–∞–≥–æ–ª–æ–≤–æ–∫ –ª–µ–∫—Ü–∏–∏ –∏–∑ –ø–µ—Ä–≤–æ–≥–æ –∑–∞–≥–æ–ª–æ–≤–∫–∞ —É—Ä–æ–≤–Ω—è 1"""
    for header in headers:
        if header['level'] == 1:
            return header['text']
    
    if headers:
        return headers[0]['text']
    
    # –ï—Å–ª–∏ –Ω–µ—Ç –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤, –±–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π –∞–±–∑–∞—Ü
    for para in paragraphs:
        if para['type'] == 'text' and para['text']:
            text = para['text'].strip()
            if text and len(text) < 200:
                return text
    
    return "–õ–µ–∫—Ü–∏—è"


def _generate_description_from_paragraphs(
    paragraphs: List[Dict[str, Any]],
    headers: List[Dict[str, Any]]
) -> str:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ–ø–∏—Å–∞–Ω–∏–µ –∏–∑ –ø–µ—Ä–≤—ã—Ö 1-2 —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –∞–±–∑–∞—Ü–µ–≤ (–Ω–µ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤)"""
    description_parts = []
    header_indices = {h['index'] for h in headers}
    
    for i, para in enumerate(paragraphs):
        if para['type'] != 'text' or not para['text'] or i in header_indices:
            continue
        
        text = para['text'].strip()
        if not text or len(text) < 10:
            continue
        
        description_parts.append(text)
        combined = " ".join(description_parts)
        if len(description_parts) >= 2 or len(combined) > 500:
            break
    
    if description_parts:
        description = " ".join(description_parts)
        if len(description) > 500:
            description = description[:497] + "..."
        return description
    
    return ""


def _detect_language_from_paragraphs(paragraphs: List[Dict[str, Any]]) -> str:
    """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç —è–∑—ã–∫ —Ç–µ–∫—Å—Ç–∞"""
    all_text = []
    for para in paragraphs:
        if para['type'] == 'text' and para['text']:
            text = para['text'].strip()
            if text and len(text) > 3:
                all_text.append(text)
    
    if not all_text:
        return "ru"
    
    combined_text = " ".join(all_text[:10])
    cyrillic_count = sum(1 for char in combined_text if '\u0400' <= char <= '\u04FF')
    latin_count = sum(1 for char in combined_text if char.isalpha() and ord(char) < 128 and char.isascii())
    
    if cyrillic_count > latin_count * 0.3:
        return "ru"
    else:
        return "en"


def _extract_keywords_from_paragraphs(
    paragraphs: List[Dict[str, Any]],
    headers: List[Dict[str, Any]]
) -> List[str]:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏–∑ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –∏ —á–∞—Å—Ç—ã—Ö —Å–ª–æ–≤"""
    keywords = []
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ –∫–∞–∫ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
    for header in headers:
        if header['level'] == 1:
            keywords.append(header['text'])
    
    return keywords[:10]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ 10


def _build_sections_from_paragraphs(
    paragraphs: List[Dict[str, Any]],
    headers: List[Dict[str, Any]],
    header_threshold: float,
    images: List[ParsedElement]
) -> List[LectureSection]:
    """
    –ì—Ä—É–ø–ø–∏—Ä—É–µ—Ç –∞–±–∑–∞—Ü—ã –ø–æ —Ä–∞–∑–¥–µ–ª–∞–º –∏ —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º.
    
    –ö–∞–∂–¥—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ —É—Ä–æ–≤–Ω—è 1 —Å–æ–∑–¥–∞–µ—Ç –æ—Ç–¥–µ–ª—å–Ω—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É.
    """
    sections = []
    
    if not headers:
        # –ù–µ—Ç –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ - –æ–¥–Ω–∞ —Å–µ–∫—Ü–∏—è, –æ–¥–Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∞
        section = LectureSection(
            id=str(uuid.uuid4()),
            title="–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ",
            order=1
        )
        page = _build_single_page_from_paragraphs(paragraphs, "–°—Ç—Ä–∞–Ω–∏—Ü–∞ 1", 1, headers, images)
        section.add_page(page)
        sections.append(section)
        return sections
    
    # –°–æ–∑–¥–∞–µ–º –æ–¥–Ω—É —Å–µ–∫—Ü–∏—é "–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ" –∏ –¥–æ–±–∞–≤–ª—è–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∑–∞–≥–æ–ª–æ–≤–∫–∞ —É—Ä–æ–≤–Ω—è 1
    section = LectureSection(
        id=str(uuid.uuid4()),
        title="–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ",
        order=1
    )
    
    # –ù–∞—Ö–æ–¥–∏–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ —É—Ä–æ–≤–Ω—è 1
    level_1_headers = [h for h in headers if h['level'] == 1]
    
    if not level_1_headers:
        # –ù–µ—Ç –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ —É—Ä–æ–≤–Ω—è 1 - –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏
        level_1_headers = headers
    
    # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∑–∞–≥–æ–ª–æ–≤–∫–∞ —É—Ä–æ–≤–Ω—è 1
    page_counter = 1
    for header_idx, header in enumerate(level_1_headers):
        para_index = header['index']
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–Ω–µ—Ü —Å—Ç—Ä–∞–Ω–∏—Ü—ã (–Ω–∞—á–∞–ª–æ —Å–ª–µ–¥—É—é—â–µ–≥–æ –∑–∞–≥–æ–ª–æ–≤–∫–∞ –∏–ª–∏ –∫–æ–Ω–µ—Ü —Å–ø–∏—Å–∫–∞)
        if header_idx + 1 < len(level_1_headers):
            next_para_index = level_1_headers[header_idx + 1]['index']
        else:
            next_para_index = len(paragraphs)
        
        # –ê–±–∑–∞—Ü—ã —Ç–µ–∫—É—â–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã (–≤–∫–ª—é—á–∞—è –∑–∞–≥–æ–ª–æ–≤–æ–∫)
        page_paragraphs = paragraphs[para_index:next_para_index]
        
        if not page_paragraphs:
            continue
        
        # –ó–∞–≥–æ–ª–æ–≤–æ–∫ —Å—Ç—Ä–∞–Ω–∏—Ü—ã - —Ç–µ–∫—Å—Ç –∑–∞–≥–æ–ª–æ–≤–∫–∞
        page_title = header['text'].strip()[:100]
        
        # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º global_index –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
        page = _build_single_page_from_paragraphs(page_paragraphs, page_title, page_counter, headers, images)
        section.add_page(page)
        page_counter += 1
    
    sections.append(section)
    return sections


def _build_single_page_from_paragraphs(
    paragraphs: List[Dict[str, Any]],
    title: str,
    order: int,
    all_headers: List[Dict[str, Any]],
    all_images: List[ParsedElement]
) -> LecturePage:
    """
    –§–æ—Ä–º–∏—Ä—É–µ—Ç –æ–¥–Ω—É —Å—Ç—Ä–∞–Ω–∏—Ü—É –∏–∑ –∞–±–∑–∞—Ü–µ–≤.
    
    –ò—Å–∫–ª—é—á–∞–µ—Ç –∑–∞–≥–æ–ª–æ–≤–∫–∏ –∏–∑ content_blocks.
    –ü—Ä–∏–≤—è–∑—ã–≤–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∫ –∞–±–∑–∞—Ü–∞–º.
    """
    page = LecturePage(
        id=str(uuid.uuid4()),
        title=title,
        order=order
    )
    
    # –°–Ω–∞—á–∞–ª–∞ —Å—Ç—Ä–æ–∏–º —Å–ø–∏—Å–æ–∫ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –∞–±–∑–∞—Ü–µ–≤ (–∏—Å–∫–ª—é—á–∞—è –∑–∞–≥–æ–ª–æ–≤–∫–∏)
    text_paragraphs = []
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º global_index –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
    header_global_indices = {h['index'] for h in all_headers}
    
    for para in paragraphs:
        if para['type'] != 'text':
            continue
        
        # –ò—Å–∫–ª—é—á–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ –∏–∑ content_blocks, –∏—Å–ø–æ–ª—å–∑—É—è global_index
        global_idx = para.get('global_index', -1)
        is_header_para = para.get('is_header', False) or global_idx in header_global_indices
        
        if is_header_para:
            continue  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏
        
        text_paragraphs.append(para)
    
    # –°–æ–∑–¥–∞–µ–º TextBlock –∏–∑ –∫–∞–∂–¥–æ–≥–æ –∞–±–∑–∞—Ü–∞
    # TextBlock –¥–æ–ª–∂–µ–Ω —Ö—Ä–∞–Ω–∏—Ç—å —Å—Å—ã–ª–∫—É –Ω–∞ –∏—Å—Ö–æ–¥–Ω—ã–π –∞–±–∑–∞—Ü
    for para in text_paragraphs:
        text_block = TextBlock(
            content=para['text'],
            params={
                "font_size": para['avg_font_size'],
                "bold": para['is_bold'],
                "alignment": "left",
                "source_paragraph": para  # —Å—Å—ã–ª–∫–∞ –Ω–∞ –∏—Å—Ö–æ–¥–Ω—ã–π –∞–±–∑–∞—Ü
            }
        )
        page.add_block(text_block)
    
    # –ü—Ä–∏–≤—è–∑—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∫ –∞–±–∑–∞—Ü–∞–º –∏ –≤—Å—Ç—Ä–∞–∏–≤–∞–µ–º inline
    # –§–∏–ª—å—Ç—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–µ –æ—Ç–Ω–æ—Å—è—Ç—Å—è –∫ —ç—Ç–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ
    page_images = []
    for img in all_images:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∫ —ç—Ç–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ
        if paragraphs:
            first_para_page = paragraphs[0].get('page_number', 0)
            last_para_page = paragraphs[-1].get('page_number', 0)
            if first_para_page <= img.page_number <= last_para_page:
                page_images.append(img)
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≤—ã—Å–æ—Ç—É —Å—Ç—Ä–∞–Ω–∏—Ü—ã –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ä–∞–∑–º–µ—Ä–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –≤—ã—Å–æ—Ç—É –∏–∑ –∞–±–∑–∞—Ü–µ–≤ –∏–ª–∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—É—é –≤—ã—Å–æ—Ç—É A4 (842px –ø—Ä–∏ 72 DPI)
    page_height = 842.0  # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –≤—ã—Å–æ—Ç–∞ A4
    if paragraphs:
        max_y = max(
            (p['bbox'][3] if p.get('bbox') and len(p.get('bbox', [])) >= 4 else 0)
            for p in paragraphs
        )
        if max_y > 0:
            page_height = max_y
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ –ø–æ–∑–∏—Ü–∏–∏ Y –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –ø–æ—Ä—è–¥–∫–∞ –≤—Å—Ç–∞–≤–∫–∏
    page_images.sort(key=lambda img: img.bbox[1] if img.bbox and len(img.bbox) >= 4 else 0)
    
    for img in page_images:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º bbox –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        if not img.bbox or len(img.bbox) < 4:
            continue
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º image_path: –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å SCORM-safe –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–º –ø—É—Ç—ë–º –∫ —Ñ–∞–π–ª—É
        # –ï—Å–ª–∏ –ø—É—Ç—å –ø—É—Å—Ç–æ–π –∏–ª–∏ blob URL, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º (blob URL –Ω–µ –º–æ–≥—É—Ç –±—ã—Ç—å –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã –≤ Python)
        if not img.image_path:
            logging.warning(f"‚ö†Ô∏è –ü—É—Å—Ç–æ–π image_path –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–ø—Ä–æ–ø—É—â–µ–Ω–æ)")
            continue
        
        # Blob URL –Ω–µ –º–æ–≥—É—Ç –±—ã—Ç—å –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã –≤ Python (—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã –¥–ª—è –±—Ä–∞—É–∑–µ—Ä–∞)
        # –¢–∞–∫–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã –Ω–∞ —ç—Ç–∞–ø–µ –ø–∞—Ä—Å–∏–Ω–≥–∞
        if img.image_path.startswith("blob:"):
            logging.error(f"‚ùå Blob URL –≤ lecture_builder: {img.image_path} (–Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –æ–±—Ä–∞–±–æ—Ç–∞–Ω, –ø—Ä–æ–ø—É—â–µ–Ω–æ)")
            continue
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        img_height = img.bbox[3] - img.bbox[1]
        img_relative_height = (img_height / page_height) * 100 if page_height > 0 else 0
        
        # –ö—Ä–∏—Ç–µ—Ä–∏–π 4: –û—Ç–¥–µ–ª—å–Ω—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É —Å–æ–∑–¥–∞–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ –¥–ª—è –æ—á–µ–Ω—å –±–æ–ª—å—à–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        # (>60-70% –≤—ã—Å–æ—Ç—ã —Å—Ç—Ä–∞–Ω–∏—Ü—ã) –∏ –±–µ–∑ –±–ª–∏–∑–∫–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤
        is_very_large = img_relative_height > 60
        
        if is_very_large:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –±–ª–∏–∑–∫–∏–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã
            has_nearby_text = False
            for para in text_paragraphs:
                if para.get('bbox') and len(para.get('bbox', [])) >= 4:
                    para_bbox = para['bbox']
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ –∏–ª–∏ –±–ª–∏–∑–æ—Å—Ç—å –ø–æ Y
                    img_center_y = (img.bbox[1] + img.bbox[3]) / 2
                    para_center_y = (para_bbox[1] + para_bbox[3]) / 2
                    distance = abs(img_center_y - para_center_y)
                    if distance < 100:  # –ë–ª–∏–∑–∫–æ –∫ —Ç–µ–∫—Å—Ç—É
                        has_nearby_text = True
                        break
            
            if not has_nearby_text:
                # –û—á–µ–Ω—å –±–æ–ª—å—à–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –±–µ–∑ –±–ª–∏–∑–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º (–Ω–µ –≤—Å—Ç—Ä–∞–∏–≤–∞–µ–º inline)
                # –ú–æ–∂–Ω–æ —Å–æ–∑–¥–∞—Ç—å –æ—Ç–¥–µ–ª—å–Ω—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É –ø–æ–∑–∂–µ, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                continue
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ–∑–∏—Ü–∏—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –±–ª–æ–∫–æ–≤ –ø–æ Y
        img_y_top = img.bbox[1]
        img_y_bottom = img.bbox[3]
        
        # –ù–∞—Ö–æ–¥–∏–º –∞–±–∑–∞—Ü, –∫ –∫–æ—Ç–æ—Ä–æ–º—É –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        # –ï—Å–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–∏–∂–µ –∞–±–∑–∞—Ü–∞ A –∏ –≤—ã—à–µ –∞–±–∑–∞—Ü–∞ B, –æ—Ç–Ω–æ—Å–∏–º –∫ –∞–±–∑–∞—Ü—É A
        target_block_idx = None
        
        for i, block in enumerate(page.content_blocks):
            if not isinstance(block, TextBlock):
                continue
            
            source_para = block.params.get('source_paragraph')
            if not source_para or not source_para.get('bbox') or len(source_para.get('bbox', [])) < 4:
                continue
            
            para_bbox = source_para['bbox']
            para_y_bottom = para_bbox[3]
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–∏–∂–µ —ç—Ç–æ–≥–æ –∞–±–∑–∞—Ü–∞
            if img_y_top >= para_y_bottom:
                # –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–∏–∂–µ —ç—Ç–æ–≥–æ –∞–±–∑–∞—Ü–∞
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ—Ç –ª–∏ —Å–ª–µ–¥—É—é—â–µ–≥–æ –∞–±–∑–∞—Ü–∞, –∫–æ—Ç–æ—Ä—ã–π –≤—ã—à–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                next_para_found = False
                for j in range(i + 1, len(page.content_blocks)):
                    next_block = page.content_blocks[j]
                    if isinstance(next_block, TextBlock):
                        next_source_para = next_block.params.get('source_paragraph')
                        if next_source_para and next_source_para.get('bbox') and len(next_source_para.get('bbox', [])) >= 4:
                            next_para_bbox = next_source_para['bbox']
                            next_para_y_top = next_para_bbox[1]
                            # –ï—Å–ª–∏ —Å–ª–µ–¥—É—é—â–∏–π –∞–±–∑–∞—Ü –≤—ã—à–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, —Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –º–µ–∂–¥—É –Ω–∏–º–∏
                            if next_para_y_top > img_y_bottom:
                                # –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –º–µ–∂–¥—É —Ç–µ–∫—É—â–∏–º –∏ —Å–ª–µ–¥—É—é—â–∏–º –∞–±–∑–∞—Ü–µ–º
                                target_block_idx = i
                                break
                            else:
                                # –°–ª–µ–¥—É—é—â–∏–π –∞–±–∑–∞—Ü –Ω–∏–∂–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –ø–æ–∏—Å–∫
                                continue
                
                if not next_para_found:
                    # –ù–µ—Ç —Å–ª–µ–¥—É—é—â–µ–≥–æ –∞–±–∑–∞—Ü–∞ –∏–ª–∏ –æ–Ω –Ω–∏–∂–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è - –æ—Ç–Ω–æ—Å–∏–º –∫ —Ç–µ–∫—É—â–µ–º—É
                    target_block_idx = i
                    break
        
        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –ø–æ–∑–∏—Ü–∏—é –ø–æ Y, –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–ª–∏–∂–∞–π—à–∏–π –±–ª–æ–∫
        if target_block_idx is None:
            target_block_idx = _find_nearest_text_block_for_image(page, img, text_paragraphs)
        
        # –í—Å—Ç–∞–≤–ª—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ inline –º–µ–∂–¥—É TextBlock'–∞–º–∏
        # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –ø—É—Ç—å –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å images/ (–¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —É–∂–µ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω –≤ _normalize_image_paths)
        image_path = img.image_path
        if not image_path.startswith("images/"):
            # –ï—Å–ª–∏ –ø—É—Ç—å –Ω–µ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å images/, –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –µ–≥–æ
            image_filename = Path(image_path).name
            image_path = f"images/{image_filename}"
            logging.warning(f"‚ö†Ô∏è –ü—É—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ ImageBlock: {img.image_path} -> {image_path}")
        
        if target_block_idx is not None:
            image_block = ImageBlock(
                content=image_path,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π –ø—É—Ç—å –∏–∑ images/
                params={
                    "alt": "",
                    "width": img.bbox[2] - img.bbox[0],
                    "height": img.bbox[3] - img.bbox[1],
                }
            )
            page.content_blocks.insert(target_block_idx + 1, image_block)
        else:
            # –ù–µ—Ç —Ç–µ–∫—Å—Ç–∞ —Ä—è–¥–æ–º - –¥–æ–±–∞–≤–ª—è–µ–º –≤ –∫–æ–Ω–µ—Ü
            image_block = ImageBlock(
                content=image_path,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π –ø—É—Ç—å –∏–∑ images/
                params={
                    "alt": "",
                    "width": img.bbox[2] - img.bbox[0],
                    "height": img.bbox[3] - img.bbox[1],
                }
            )
            page.add_block(image_block)
    
    return page


def _find_nearest_text_block_for_image(
    page: LecturePage,
    image: ParsedElement,
    text_paragraphs: List[Dict[str, Any]]
) -> Optional[int]:
    """
    –ù–∞—Ö–æ–¥–∏—Ç –±–ª–∏–∂–∞–π—à–∏–π TextBlock –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é –ø–æ bbox.
    
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç source_paragraph –∏–∑ TextBlock, –∞ –Ω–µ –∏–Ω–¥–µ–∫—Å.
    
    Returns:
        –ò–Ω–¥–µ–∫—Å –±–ª–∏–∂–∞–π—à–µ–≥–æ TextBlock –∏–ª–∏ None
    """
    if not image.bbox or len(image.bbox) < 4:
        return None
    
    image_center_y = (image.bbox[1] + image.bbox[3]) / 2
    
    nearest_idx = None
    min_distance = float('inf')
    
    # –ò—â–µ–º TextBlock'–∏ –∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º source_paragraph –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è
    for i, block in enumerate(page.content_blocks):
        if not isinstance(block, TextBlock):
            continue
        
        # –ü–æ–ª—É—á–∞–µ–º source_paragraph –∏–∑ params
        source_para = block.params.get('source_paragraph')
        if source_para and source_para.get('bbox') and len(source_para['bbox']) >= 4:
            para_center_y = (source_para['bbox'][1] + source_para['bbox'][3]) / 2
            distance = abs(para_center_y - image_center_y)
            
            if distance < min_distance:
                min_distance = distance
                nearest_idx = i
    
    # –ï—Å–ª–∏ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–µ (> 300px), —Å—á–∏—Ç–∞–µ–º —á—Ç–æ —Ç–µ–∫—Å—Ç–∞ —Ä—è–¥–æ–º –Ω–µ—Ç
    if min_distance > 300:
        return None
    
    return nearest_idx


def _build_lecture_from_images_only(elements: List[ParsedElement]) -> Lecture:
    """–°–æ–∑–¥–∞–µ—Ç –ª–µ–∫—Ü–∏—é —Ç–æ–ª—å–∫–æ –∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (–µ—Å–ª–∏ –Ω–µ—Ç —Ç–µ–∫—Å—Ç–∞)"""
    lecture = Lecture(
        title="–õ–µ–∫—Ü–∏—è",
        description="",
        language="ru"
    )
    
    section = LectureSection(
        id=str(uuid.uuid4()),
        title="–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ",
        order=1
    )
    
    page = LecturePage(
        id=str(uuid.uuid4()),
        title="–°—Ç—Ä–∞–Ω–∏—Ü–∞ 1",
        order=1
    )
    
    # –†–∞–∑–º–µ—â–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    for elem in elements:
        if elem.type == "image":
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º image_path: –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å SCORM-safe –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–º –ø—É—Ç—ë–º –∫ —Ñ–∞–π–ª—É
            if not elem.image_path:
                logging.warning(f"‚ö†Ô∏è –ü—É—Å—Ç–æ–π image_path –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–ø—Ä–æ–ø—É—â–µ–Ω–æ)")
                continue
            
            # Blob URL –Ω–µ –º–æ–≥—É—Ç –±—ã—Ç—å –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã –≤ Python (—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã –¥–ª—è –±—Ä–∞—É–∑–µ—Ä–∞)
            if elem.image_path.startswith("blob:"):
                logging.error(f"‚ùå Blob URL –≤ lecture_builder: {elem.image_path} (–Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –æ–±—Ä–∞–±–æ—Ç–∞–Ω, –ø—Ä–æ–ø—É—â–µ–Ω–æ)")
                continue
            
            # ImageBlock —Å–æ–∑–¥–∞–µ—Ç—Å—è —Å –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–º –ø—É—Ç—ë–º –¥–ª—è SCORM-–ø–∞–∫–µ—Ç–∞
            # –ü—É—Ç—å –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–º –æ—Ç –∫–æ—Ä–Ω—è –ø–∞–∫–µ—Ç–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, "images/img_1.png")
            # –ü—É—Ç—å —É–∂–µ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω –≤ _normalize_image_paths, –Ω–æ –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π
            image_path = elem.image_path
            if not image_path or not image_path.startswith("images/"):
                # –ï—Å–ª–∏ –ø—É—Ç—å –Ω–µ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å images/, –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –µ–≥–æ
                if image_path:
                    image_filename = Path(image_path).name
                    image_path = f"images/{image_filename}"
                else:
                    logging.warning(f"‚ö†Ô∏è –ü—É—Å—Ç–æ–π image_path –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –ø—Ä–æ–ø—É—â–µ–Ω–æ")
                    continue
            
            image_block = ImageBlock(
                content=image_path,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π –ø—É—Ç—å –∏–∑ images/
                params={"alt": ""}
            )
            page.add_block(image_block)
            logging.debug(f"üìå –î–æ–±–∞–≤–ª–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É: {image_path}")
    
    section.add_page(page)
    lecture.add_section(section)
    
    return lecture
